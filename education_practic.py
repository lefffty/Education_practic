# -*- coding: utf-8 -*-
"""education practic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MxcD-1GqzQ06nCyH85IYh9TQxWBiXtOv

# **1. Загрузка датасета в библиотеку Pandas.**
"""

import pandas as pd
import numpy as np

neg_tweets = pd.read_csv("/content/drive/MyDrive/negative.csv")

pos_tweets = pd.read_csv("/content/drive/MyDrive/positive.csv")

pos_tweets = pos_tweets[['tweet', 'class']]
neg_tweets = neg_tweets[['tweet', 'class']]
print(f"Positive tweets shape: {pos_tweets.shape}")
print(f"Negative tweets shape: {neg_tweets.shape}")

"""# **2. Лемматизация и удаление стоп-слов.**

Лемматизация - процесс приведения словоформы к лемме — её нормальной (словарной) форме. Алгоритмы лемматизации на языке python реализованы, например, в библиотеке NLTK.
"""

import nltk

nltk.download('stopwords')

!pip install pymorphy2

import re

from pymorphy2 import MorphAnalyzer
from nltk.corpus import stopwords

patterns = "[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\]^_`{|}~—\"\-]+"
stopwords_ru = stopwords.words('russian')
morph = MorphAnalyzer()

def lemmatize(doc: pd.DataFrame):
    doc = re.sub(patterns, ' ', doc)
    tokens = []
    for token in doc.split():
        if token and token not in stopwords_ru:
            token = token.strip()
            token = morph.normal_forms(token)[0]
            tokens.append(token)

    if len(tokens) > 2:
        return tokens
    return None

pos_data = pos_tweets.iloc[:, 0]
neg_data = neg_tweets.iloc[:, 0]
pos_data = pos_data.apply(lemmatize)
neg_data = neg_data.apply(lemmatize)

pos_data = pos_data.to_frame()
neg_data = neg_data.to_frame()

neg_data = neg_data.assign(cl = 0)
neg_data

pos_data = pos_data.assign(cl = 1)
pos_data

pos_data = pos_data.dropna(ignore_index=True)
pos_data

neg_data = neg_data.dropna(ignore_index=True)
neg_data

result_df = pd.concat([pos_data, neg_data])
result_df

result_df = result_df.sample(frac=1).reset_index(drop=True)
result_df

"""# **3. Разбиение на тренировочную и тестовую выборки.**"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer

x_train, x_test, y_train, y_test = train_test_split(result_df['tweet'], result_df['cl'], random_state=42, test_size=0.2)

x_train = [str(element) for element in x_train]

x_test = [str(element) for element in x_test]

"""# **4. CountVectorizer**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

"""**1. Униграммы**"""

vectorizer_unigram = CountVectorizer(lowercase=False)
x_train_unigram_cv = vectorizer_unigram.fit_transform(x_train)
x_test_unigram_cv = vectorizer_unigram.transform(x_test)

unigram_lr = LogisticRegression(random_state=42)
unigram_lr.fit(x_train_unigram_cv, y_train)

y_pred_unigram = unigram_lr.predict(x_test_unigram_cv)

print(classification_report(y_test, y_pred_unigram))

"""**2. Биграммы**"""

vectorizer_bigram = CountVectorizer(lowercase=False, ngram_range=(2,2))
x_train_bigram_cv = vectorizer_bigram.fit_transform(x_train)
x_test_bigram_cv = vectorizer_bigram.transform(x_test)

bigram_lr = LogisticRegression(random_state=42)

bigram_lr.fit(x_train_bigram_cv, y_train)

y_pred_bigram = bigram_lr.predict(x_test_bigram_cv)

print(classification_report(y_test, y_pred_bigram))

"""**3. Триграммы**"""

vectorizer_trigram = CountVectorizer(lowercase=False, ngram_range=(3,3))
x_train_trigram_cv = vectorizer_bigram.fit_transform(x_train)
x_test_trigram_cv = vectorizer_bigram.transform(x_test)

trigram_lr = LogisticRegression(random_state=42)

trigram_lr.fit(x_train_trigram_cv, y_train)

y_pred_trigram = trigram_lr.predict(x_test_trigram_cv)

print(classification_report(y_test, y_pred_trigram))

"""# **5. TfidfVectorizer**

$$
TFIDF(t,d) = TF(t,d) * IDF(t)
$$

$$
IDF(t) = {ln(\frac{n}{DF(t)}) + 1}
$$
"""

from sklearn.feature_extraction.text import TfidfVectorizer

"""

**1.   Униграммы**

"""

tfidf_vectorizer_unigram = TfidfVectorizer(lowercase=False, ngram_range=(1,1))
x_train_unigram_tfidf = tfidf_vectorizer_unigram.fit_transform(x_train)
x_test_unigram_tfidf = tfidf_vectorizer_unigram.transform(x_test)

tfidf_unigram_lr = LogisticRegression(random_state=42)
tfidf_unigram_lr.fit(x_train_unigram_tfidf, y_train)

y_pred_unigram_tfidf = tfidf_unigram_lr.predict(x_test_unigram_tfidf)

print(classification_report(y_test, y_pred_unigram_tfidf))

"""**2. Биграммы**"""

tfidf_vectorizer_bigram = TfidfVectorizer(lowercase=False, ngram_range=(2,2))
x_train_bigram_tfidf = tfidf_vectorizer_bigram.fit_transform(x_train)
x_test_bigram_tfidf = tfidf_vectorizer_bigram.transform(x_test)

tfidf_bigram_lr = LogisticRegression(random_state=42)
tfidf_bigram_lr.fit(x_train_bigram_tfidf, y_train)

y_pred_bigram_tfidf = tfidf_bigram_lr.predict(x_test_bigram_tfidf)

print(classification_report(y_test, y_pred_bigram_tfidf))

"""

**3. Триграммы**"""

tfidf_vectorizer_trigram = TfidfVectorizer(lowercase=False, ngram_range=(3,3))
x_train_trigram_tfidf = tfidf_vectorizer_trigram.fit_transform(x_train)
x_test_trigram_tfidf = tfidf_vectorizer_trigram.transform(x_test)

tfidf_trigram_lr = LogisticRegression(random_state=42)
tfidf_trigram_lr.fit(x_train_trigram_tfidf, y_train)

y_pred_trigram_tfidf = tfidf_trigram_lr.predict(x_test_trigram_tfidf)

print(classification_report(y_test, y_pred_trigram_tfidf))

"""# **6. Результаты**"""

cv_results = dict()

cv_results['unigram'] = 0.73
cv_results['bigram'] =  0.66
cv_results['trigram'] = 0.66

tfidf_results = dict()

tfidf_results['unigram'] = 0.73
tfidf_results['bigram'] = 0.66
tfidf_results['trigram'] = 0.51

average_tfidf = sum(tfidf_results.values())/len(tfidf_results)
average_tfidf

average_cv = sum(cv_results.values())/len(cv_results.values())
average_cv